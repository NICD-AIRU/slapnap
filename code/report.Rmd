---
title: 'SLAPNAP Report: `r format(strsplit(Sys.getenv("Nab"), split = ";")[[1]])`'
author: "SLAPNAP Team"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: bookdown::html_document2
---

```{r setup, include=FALSE}
source("/home/lib/report_preamble.R")
```

```{r load_cvfit_objects}
cvfit_ic50 <- readRDS("/home/slfits/cvfit_pc.ic50.rds")
class(cvfit_ic50) <- "myCV.SuperLearner"
if(!reduce_outcomes){
	cvfit_ic80 <- readRDS("/home/slfits/cvfit_pc.ic80.rds")
	cvfit_iip <- readRDS("/home/slfits/cvfit_iip.rds")
	cvfit_dichotomous.1 <- readRDS("/home/slfits/cvfit_dichotomous.1.rds")
	cvfit_dichotomous.2 <- readRDS("/home/slfits/cvfit_dichotomous.2.rds")
	class(cvfit_ic80) <- class(cvfit_iip) <- class(cvfit_dichotomous.1) <- 
		class(cvfit_dichotomous.2) <- "myCV.SuperLearner"
}

rslt_ic50 <- get_est_and_ci(cvfit_ic50, Rsquared = TRUE)
rslt_ic80 <- get_est_and_ci(cvfit_ic80, Rsquared = TRUE)
rslt_iip <- get_est_and_ci(cvfit_iip, Rsquared = TRUE)
rslt_dichot1 <- get_est_and_ci(cvfit_dichotomous.1)
rslt_dichot2 <- get_est_and_ci(cvfit_dichotomous.2)

# # get summary measures for executive summary
# sum_ic50 <- summary(cvfit_ic50, Rsquared = TRUE, method = "method.CC_LS")
# sum_ic80 <- summary(cvfit_ic80, Rsquared = TRUE, method = "method.CC_LS")
# sum_iip <- summary(cvfit_iip, Rsquared = TRUE, method = "method.CC_LS")
# sum_dichot1 <- summary(cvfit_dichotomous.1, Rsquared = FALSE, method = "method.AUC")
# sum_dichot2 <- summary(cvfit_dichotomous.2, Rsquared = FALSE, method = "method.AUC")
```

# Executive summary

The NAbs studied in this analysis are `r antibodies`. There were `r n_row_prev` observations extracted from the CATNAP database. There were `r n_row_now` observations with complete sequence data that were used in the analysis. 

```{r rsquaredtable}
rsqtab <- rbind(unlist(rslt_ic50), unlist(rslt_ic80), unlist(rslt_iip))
row.names(rsqtab) <- c("IC-50","IC-80","IIP")
kable(rsqtab, col.names = c(expression(CV-R^2), "Lower 95% CI", "Upper 95% CI"),
      digits = 3, row.names = TRUE,
      caption = "Estimates of cross-validated R-squared for super learner predictions of the three continuous-valued outcomes")
```

```{r auctable}
auctab <- rbind(unlist(rslt_dichot1), unlist(rslt_dichot2))
row.names(auctab) <- c("Estimated sensitivity", "Multiple sensitivity")
kable(auctab, col.names = c("CV-AUC", "Lower 95% CI", "Upper 95% CI"),
      digits = 3, row.names = TRUE, 
      caption = "Estimates of cross-validated AUC for super learner predictions of the two dichotomous outcomes")
```

The estimated cross-validated $R^2$ of the super learner for predicting continuous outcomes are shown in Table \@ref(tab:rsquaredtable). The estimated cross-validated $R^2$ of the super learner for predicting binary sensitivity measures are shown in Table \@ref(tab:auctable).

<!--
	Something here about variable importance 
-->

# Summary of endpoints 

Histograms of IC-50 and IC-80 for each individual NAb are shown in Figure \@ref(fig:histic50) and Figure \@ref(fig:histic80), respectively. Related summaries are shown in Table \@ref(tab:tableic50) and Table \@ref(tab:tableic80). 

Histograms for the predicted IC-50 an IC-80 based on the additive model are shown in Figure \@ref(fig:histcombn), a histogram of the predicted IIP is shown in Figure \@ref(fig:histiip), and related summaries are shown in Table \@ref(tab:combntable). The distribution of the two binary sensitivity measures is shown in Figure \@ref(fig:dichot). 

```{r histic50, fig.cap = "Histogram of IC50 values for individual NAbs", fig.height=5}
ic50_hist <- list()
ic50_tab <- list()
ct <- 0
for(i in seq_len(n_ab)){
	ct <- ct + 1
	this_name <- gsub("-", ".", paste0(antibodies[i], ".ic50.imputed"))
	ic50_hist[[ct]] <- make_hist_plot(dat, var_name = this_name, 
	                                  x_lab = paste0("IC-50 ", antibodies[i]),
	                                  y_lab = "Density")
	ic50_tab[[ct]] <- summary(dat[, this_name])[1:6] # to ignore NA columns
	ct <- ct+1
 	dat[,paste0("log10_",this_name)] <- log10(dat[, this_name])
 	ic50_hist[[ct]] <- make_hist_plot(dat, var_name = paste0("log10_",this_name),
 	                                  x_lab = bquote(log[10]~"(IC-50 "~.(antibodies[i])~")"),
 	                                  y_lab = "") 	
 	ic50_tab[[ct]] <- summary(dat[, paste0("log10_",this_name)])[1:6]
}
do.call(grid.arrange, ic50_hist)
```

```{r tableic50}
ic50_table <- Reduce(rbind, ic50_tab)
row.names(ic50_table) <- c(paste0("IC-50 ", antibodies), 
                           paste0("log(IC-50 ", antibodies,")"))[c(seq(1,n_ab*2,by=2),seq(2, n_ab*2, by = 2))]
kable(ic50_table, row.names = TRUE, digits = 3,
      caption = "Summary statistics of IC-50 values for individual NAbs")
```

```{r histic80, fig.cap = "Histogram of IC80 values for individual NAbs"}
ic80_hist <- list()
ic80_tab <- list()
ct <- 0
for(i in seq_len(n_ab)){
	ct <- ct + 1
	this_name <- gsub("-", ".", paste0(antibodies[i], ".ic80.imputed"))
	ic80_hist[[ct]] <- make_hist_plot(dat, var_name = this_name, 
	                                  x_lab = paste0("IC-80 ", antibodies[i]),
	                                  y_lab = "Density")
	ic80_tab[[ct]] <- summary(dat[, this_name])[1:6] # to ignore NA columns
	ct <- ct+1
 	dat[,paste0("log10_",this_name)] <- log10(dat[, this_name])
 	ic80_hist[[ct]] <- make_hist_plot(dat, var_name = paste0("log10_",this_name), 
	                                  x_lab = bquote(log[10]~"(IC-80 "~.(antibodies[i])~")"),
	                                  y_lab = "")
 	ic80_tab[[ct]] <- summary(dat[, paste0("log10_",this_name)])[1:6]
}
do.call(grid.arrange, ic80_hist)
```

```{r tableic80}
ic80_table <- Reduce(rbind, ic80_tab)
row.names(ic80_table) <- c(paste0("IC-80 ", antibodies), 
                           paste0("log(IC-80 ", antibodies,")"))[c(seq(1,n_ab*2,by=2),seq(2, n_ab*2, by = 2))]
kable(ic80_table, row.names = TRUE, digits = 3,
      caption = "Summary statistics of IC-80 values for individual NAbs")
```


```{r histcombn, fig.cap = "Histogram of estimated IC50 and IC80 for combined NAbs. Top row = original scale; bottom row = log10 scale"}
combn_hist <- list()
combn_hist[[1]] <- make_hist_plot(dat, "pc.ic50", "Estimated IC-50", "Density")
combn_hist[[2]] <- make_hist_plot(dat, "log10.pc.ic50", bquote(log[10]~"(estimated IC-50)"), "")
combn_hist[[3]] <- make_hist_plot(dat, "pc.ic80", "Estimated IC-80", "Density")
combn_hist[[4]] <- make_hist_plot(dat, "log10.pc.ic80", bquote(log[10]~"(estimated IC-80)"), "")
do.call(grid.arrange, combn_hist)
```

```{r histiip, fig.cap = "Estimated IIP for combined NAbs"}
iip_hist <- list()
iip_hist[[1]] <- make_hist_plot(dat, "iip", "Estimated IIP", "Density")
# dat$log10.iip <- log10(dat$iip)
# iip_hist[[2]] <- make_hist_plot(dat, "log10.iip", bquote(log[10]~"(estimated IIP)"), "")
do.call(grid.arrange, iip_hist)
```

```{r combntable}
# make a table of ic50 80 and iip for combined NAbs
combn_table <- rbind(
  summary(dat$pc.ic50)[1:6],
  summary(dat$log10.pc.ic50)[1:6],
  summary(dat$pc.ic80)[1:6],
  summary(dat$log10.pc.ic80)[1:6],
  summary(dat$iip)[1:6]
)
row.names(combn_table) <- c(
  "Estimated IC-50", "log(estimated IC-50)", "Estimated IC-80", "log(estimated IC-80)", "IIP"
)
kable(combn_table, row.names = TRUE, digits = 3,
      caption = "Summaries of combined NAb endpoints")
```

```{r dichot, fig.cap = "Distribution of binary sensitivity outcomes. Estimated indicates whether the estimated IC-50 falls above a sensitivity threshold. Multiple indicates whether at least two individual NAbs fall above a sensitivity threshold."}
n <- n_row_now
# make a stacked data set for easy use of geom_bar
dichot_dat <- data.frame(
  Outcome_type = c("Estimated", "Estimated", "Multiple", "Multiple"),
  Outcome = rep(c("Resistant", "Sensitive"), 2),
  value = 100*c(mean(dat$dichotomous.1), 1 - mean(dat$dichotomous.1),
            mean(dat$dichotomous.2), 1 - mean(dat$dichotomous.2))
)
trans_fill <- c(
  rgb(30, 21, 42, alpha = 255/2, maxColorValue = 255),
  rgb(78, 103, 102, alpha = 255/2, maxColorValue = 255),
  rgb(90,177,187, alpha = 255/2, maxColorValue = 255),
  rgb(165, 200, 130, alpha = 255/2, maxColorValue = 255),
  rgb(247, 221, 114, alpha = 255/2, maxColorValue = 255)
)

fill <- c(
  rgb(30, 21, 42, maxColorValue = 255),
  rgb(78, 103, 102, maxColorValue = 255),
  rgb(90,177,187, maxColorValue = 255),
  rgb(165, 200, 130, maxColorValue = 255),
  rgb(247, 221, 114, maxColorValue = 255)
)

ggplot(dichot_dat, aes(y = value, x = factor(Outcome_type), fill = factor(Outcome))) + 
	geom_bar(position = "fill", stat = "identity") + 
	scale_fill_manual(values = fill[c(2,4)]) + 
	theme_bw() + 
	labs(fill = "") + 
	xlab("Sensitivity Measure") + 
	geom_text(data = dichot_dat, aes(y = value, label = paste0(round(value, 2), "%"), stat = "identity"), 
	          position = position_fill(vjust = 0.5)) 
```


# Super learner prediction results

```{r}
# get a fresh data set
dat <- get_dat()$dat
```

A super learner was fit to each outcome. For continuous outcomes, super learner weights were chosen to optimize estimated 10-fold cross-validated MSE; for binary outcomes, weights were chosen to optimize a 10-fold negative log-likelihood risk estimate. The algorithms used in the super learner are shown in Table \@ref(tab:superlearnerlibrarytable). 

```{r superlearnerlibrarytable}
source("/home/lib/super_learner_libraries.R")
library_table <- data.frame()
this_library <- if(reduce_library){
	default_library_reduced
}else{
	default_library
}
Description <- sapply(this_library, function(x){
	eval(parse(text = paste0("descr_", x)))
})
knitr::kable(as.data.frame(Description),
             caption = "Super learner library")
```

The weights assigned to each algorithm for each outcome are shown in Table \@ref{tab:superlearnerweighttable}. Cross-validated risks for each outcome are shown in the following subsections. 

```{r superlearnerweighttable}
# load super learner fits
outcome_names <- if(!reduce_outcomes){
	c("log10.pc.ic50", "log10.pc.ic80", "iip", "dichotomous.1", "dichotomous.2")
}else{
	c("log10.pc.ic50")
}
weight_list <- vector(mode = "list", length = length(outcome_names))
ct <- 0
for(o in outcome_names){
	ct <- ct + 1
	fit_name <- paste0("fit_", o, ".rds")
	weight_list[[ct]] <- readRDS(paste0("/home/slfits/slweights_", fit_name))
}
weight_table <- data.frame(Reduce(cbind, weight_list))
colnames(weight_table) <- outcome_names
row.names(weight_table) <- this_library
knitr::kable(as.data.frame(weight_table), digits = 2,
             caption = "Table of super learner weights for each outcome")
```

## IC-50 

The cross-validated performance of super learner (in terms of $R^2$) relative to the discrete super learner and candidate algorithms are shown for IC-50 in Figure \@ref(fig:plotic50).

```{r plotic50, fig.cap = "Cross-validated R-squared for estimated IC-50"}
plot(cvfit_ic50, main_title = "IC-50", xlim1 = -0.05, xlim2 = 0.8, text_size = 9,
     method = "method.CC_LS")
# and get correlations
cor_ic50 <- get_cor_pred_outcome(cvfit_ic50)
```

Figure \@ref(fig:plotic50predversusoutcomes) shows cross-validated predictions made by the super learner plotted against outcomes. The Pearson correlation between predictions and true outcomes was `r round(cor_ic50[1], 3)`; the Spearman correlation was `r round(cor_ic50[2], 3)`. 

```{r plotic50predversusoutcomes, fig.cap = "Cross-validated super learner predicted IC-50 plotted against actual IC-50 values. Colors correspond to different cross-validation folds"}
plot_cv_predictions(cvfit_ic50, outcome_name = "IC-50", log_axis = FALSE)
```

Figure \@ref(fig:plotic50imp) shows an animated representation of the importance of individual features for predicting estimated IC-50. To qualify as a top $x$ most important feature, the feature must satisfy two requirements: (1) it must have a Holm-adjusted p-value $<0.05$ in a model adjusting for geographic region; (2) it must be ranked as at least the $x$-th most important feature by one of the learning approaches (boosting, random forests, or LASSO). The animation visualizes the sequence in which features enter the set of important features by this definition. 

```{r plotic50imp, fig.show='animate', animation.hook=my_webm, interval=0.2, fig.width=8, aniopts='controls', fig.cap='Animated importance of features for predicting IC50'}
for(m in 1:50){
	make_ml_import_plot(dat = dat, imp_df = imp_ic50, max_import = m) 
}
```

Table \@ref(tab:tableic50imp) shows the top 15 most important features according to the two criteria described above. A feature is labeled "Sensitive" ("Resistant") if an increase in the value of that feature results in a lower (higher) value of the outcome. 

```{r tableic50imp}
# imp_ic50 is created in preamble
ic50_tab <- get_importance_table(imp_ic50, max_features = 15)
direction_resis <- get_importance_resis(ic50_tab, dat = dat, which_outcome = "log10.pc.ic50")
ic50_tab$direction <- ifelse(direction_resis, "Resistant", "Sensitive")
kable(ic50_tab, caption = "Top 10 most important features for predicting IC-50 and their importance ranks by each measure",
      col.names = c("Variable", "XGBOOST", "RF", "LASSO", "Adj. p-value", "Direction"),
      row.names = FALSE)
```

## IC-80 

The cross-validated performance of super learner (in terms of $R^2$) relative to the discrete super learner and candidate algorithms are shown for IC-80 in Figure \@ref(fig:plotic80).

```{r plotic80, fig.cap = "Cross-validated R-squared for estimated IC-80"}
plot(cvfit_ic80, main_title = "IC-80", xlim1 = -0.05, xlim2 = 1, text_size = 9,
     method = "method.CC_LS")
# and get correlations
cor_ic80 <- get_cor_pred_outcome(cvfit_ic80)
```

Figure \@ref(fig:plotic80predversusoutcomes) shows cross-validated predictions made by the super learner plotted against outcomes. The Pearson correlation between predictions and true outcomes was `r round(cor_ic80[1], 3)`; the Spearman correlation was `r round(cor_ic80[2], 3)`. 

```{r plotic80predversusoutcomes, fig.cap = "Cross-validated super learner predicted IC-80 plotted against actual IC-80 values. Colors correspond to different cross-validation folds"}
plot_cv_predictions(cvfit_ic80, outcome_name = "IC-80", log_axis = FALSE)
```

Figure \@ref(fig:plotic80imp) shows an animated representation of the importance of individual features for predicting estimate IC-80. To qualify as a top $x$ most important feature, the feature must satisfy two requirements: (1) it must have a Holm-adjusted p-value $<0.05$ in a model adjusting for geographic region; (2) it must be ranked as at least the $x$-th most important feature by one of the learning approaches (boosting, random forests, or LASSO). The animation visualizes the sequence in which features enter the set of important features by this definition. 

```{r plotic80imp, fig.show='animate', animation.hook=my_webm, interval=0.2, fig.width=8, aniopts='controls', fig.cap='Animated importance of features for predicting IC-80'}
for(m in 1:50){
	make_ml_import_plot(dat = dat, imp_df = imp_ic80, max_import = m) 
}
```

Table \@ref(tab:tableic80imp) shows the top 15 most important features according to the two criteria described above. A feature is labeled "Sensitive" ("Resistant") if an increase in the value of that feature results in a lower (higher) value of the outcome. 

```{r tableic80imp}
# imp_ic50 is created in preamble
ic80_tab <- get_importance_table(imp_ic80, max_features = 15)
direction_resis <- get_importance_resis(ic80_tab, dat = dat, which_outcome = "log10.pc.ic80")
ic80_tab$direction <- ifelse(direction_resis, "Resistant", "Sensitive")
kable(ic80_tab, caption = "Top 10 most important features for predicting IC-80 and their importance ranks by each measure",
      col.names = c("Variable", "XGBOOST", "RF", "LASSO", "Adj. p-value", "Direction"),
      row.names = FALSE)
```

## IIP

The cross-validated performance of super learner (in terms of $R^2$) relative to the discrete super learner and candidate algorithms are shown for IIP in Figure \@ref(fig:plotiip).

```{r plotiip, fig.cap = "Cross-validated R-squared for estimated IIP"}
plot(cvfit_iip, main_title = "IIP", xlim1 = -0.05, xlim2 = 1, text_size = 9,
     method = "method.CC_LS")
# and get correlations
cor_iip <- get_cor_pred_outcome(cvfit_iip)
```

Figure \@ref(fig:plotiippredversusoutcomes) shows cross-validated predictions made by the super learner plotted against outcomes. The Pearson correlation between predictions and true outcomes was `r round(cor_iip[1], 3)`; the Spearman correlation was `r round(cor_iip[2], 3)`. 

```{r plotiippredversusoutcomes, fig.cap = "Cross-validated super learner predicted IIP plotted against actual IIP values. Colors correspond to different cross-validation folds"}
plot_cv_predictions(cvfit_iip, outcome_name = "IIP", log_axis = FALSE)
```

Figure \@ref(fig:plotiipimp) shows an animated representation of the importance of individual features for predicting estimate IC-80. To qualify as a top $x$ most important feature, the feature must satisfy two requirements: (1) it must have a Holm-adjusted p-value $<0.05$ in a model adjusting for geographic region; (2) it must be ranked as at least the $x$-th most important feature by one of the learning approaches (boosting, random forests, or LASSO). The animation visualizes the sequence in which features enter the set of important features by this definition. 

```{r plotiipimp, fig.show='animate', animation.hook=my_webm, interval=0.2, fig.width=8, aniopts='controls', fig.cap='Animated importance of features for predicting IIP'}
for(m in 1:50){
	make_ml_import_plot(dat = dat, imp_df = imp_iip, max_import = m) 
}
```

Table \@ref(tab:tableiipimp) shows the top 15 most important features according to the two criteria described above. A feature is labeled "Sensitive" ("Resistant") if an increase in the value of that feature results in a lower (higher) value of the outcome. 

```{r tableiipimp}
# imp_ic50 is created in preamble
iip_tab <- get_importance_table(imp_iip, max_features = 15)
direction_resis <- get_importance_resis(iip_tab, dat = dat, which_outcome = "iip")
iip_tab$direction <- ifelse(direction_resis, "Resistant", "Sensitive")
kable(iip_tab, caption = "Top 10 most important features for predicting IIP and their importance ranks by each measure",
      col.names = c("Variable", "XGBOOST", "RF", "LASSO", "Adj. p-value", "Direction"),
      row.names = FALSE)
```


## Dichotomous sensitivity 1

The cross-validated performance of super learner (in terms of AUC) relative to the discrete super learner and candidate algorithms are shown for the first dichotomous endpoint (estimated IC-50 above sensitivity threshold) in Figure \@ref(fig:plotdichot1). Figure \@ref(fig:rocdichot1) shows cross-validated ROC curves for this endpoint. 

```{r plotdichot1, fig.cap = "Cross-validated AUC for predicting sensitivity based on estimated IC-50"}
plot(cvfit_dichotomous.1, main_title = "", xlim1 = 0.4, xlim2 = 1, text_size = 9,
     Rsquared = FALSE, method = "method.AUC")
```

```{r rocdichot1, fig.cap = "Cross-validated ROC curve for the super learner, discrete super learner, and single best performing algorithm for predicting sensitivity based on estimated IC-50"}
plot_roc_curves(cvfit_dichotomous.1)
```

```{r predprob1, fig.cap = "Predicted probabilities for resistant and sensitive viruses for the super learner, discrete super learner, and single best performing algorithm."}
plot_predicted_prob_boxplots(cvfit_dichotomous.1, cols = trans_fill[c(2,4)])
```

Figure \@ref(fig:plotdichot1imp) shows an animated representation of the importance of individual features for predicting estimated sensitivity . To qualify as a top $x$ most important feature, the feature must satisfy two requirements: (1) it must have a Holm-adjusted p-value $<0.05$ in a model adjusting for geographic region; (2) it must be ranked as at least the $x$-th most important feature by one of the learning approaches (boosting, random forests, or LASSO). The animation visualizes the sequence in which features enter the set of important features by this definition. 

```{r plotdichot1imp, fig.show='animate', animation.hook=my_webm, interval=0.2, fig.width=8, aniopts='controls', fig.cap='Animated importance of features for predicting estimated sensitivity'}
for(m in 1:50){
	make_ml_import_plot(dat = dat, imp_df = imp_dichot1, max_import = m) 
}
```

Table \@ref(tab:tabledichot1imp) shows the top 15 most important features according to the two criteria described above. A feature is labeled "Sensitive" ("Resistant") if an increase in the value of that feature results in a lower (higher) value of the outcome. 

```{r tabledichot1imp}
# imp_ic50 is created in preamble
dichot1_tab <- get_importance_table(imp_dichot1, max_features = 15)
direction_resis <- get_importance_resis(dichot1_tab, dat = dat, which_outcome = "dichotomous.1")
dichot1_tab$direction <- ifelse(direction_resis, "Resistant", "Sensitive")
kable(dichot1_tab, caption = "Top 10 most important features for predicting estimated sensitivity and their importance ranks by each measure",
      col.names = c("Variable", "XGBOOST", "RF", "LASSO", "Adj. p-value", "Direction"),
      row.names = FALSE)
```


## Dichotomous sensitivity 2

The cross-validated performance of super learner (in terms of AUC) relative to the discrete super learner and candidate algorithms are shown for the second dichotomous endpoint (each individual IC-50 above threshold) in Figure \@ref(fig:plotdichot2). Figure \@ref(fig:rocdichot2) shows cross-validated ROC curves for this endpoint. 

```{r plotdichot2, fig.cap = "Cross-validated AUC for predicting sensitivity based on sensitivity to individual NAbs"}
plot(cvfit_dichotomous.2, main_title = "", xlim1 = 0.4, xlim2 = 1, text_size = 9,
     Rsquared = FALSE, method = "method.AUC")
```

```{r rocdichot2, fig.cap = "Cross-validated ROC curve for the super learner, discrete super learner, and single best performing algorithm for predicting sensitivity based on sensitivity to individual NAbs"}
plot_roc_curves(cvfit_dichotomous.2)
```

Figure \@ref(fig:plotdichot2imp) shows an animated representation of the importance of individual features for predicting multiple sensitivity. To qualify as a top $x$ most important feature, the feature must satisfy two requirements: (1) it must have a Holm-adjusted p-value $<0.05$ in a model adjusting for geographic region; (2) it must be ranked as at least the $x$-th most important feature by one of the learning approaches (boosting, random forests, or LASSO). The animation visualizes the sequence in which features enter the set of important features by this definition. 

```{r plotdichot2imp, fig.show='animate', animation.hook=my_webm, interval=0.2, fig.width=8, aniopts='controls', fig.cap='Animated importance of features for predicting multiple sensitivity.'}
for(m in 1:50){
	make_ml_import_plot(dat = dat, imp_df = imp_dichot2, max_import = m) 
}
```

Table \@ref(tab:tabledichot2imp) shows the top 15 most important features according to the two criteria described above. A feature is labeled "Sensitive" ("Resistant") if an increase in the value of that feature results in a lower (higher) value of the outcome. 

```{r tabledichot2imp}
# imp_ic50 is created in preamble
dichot2_tab <- get_importance_table(imp_dichot2, max_features = 15)
direction_resis <- get_importance_resis(dichot2_tab, dat = dat, which_outcome = "dichotomous.2")
dichot2_tab$direction <- ifelse(direction_resis, "Resistant", "Sensitive")
kable(dichot2_tab, caption = "Top 10 most important features for predicting multiple sensitivity and their importance ranks by each measure",
      col.names = c("Variable", "XGBOOST", "RF", "LASSO", "Adj. p-value", "Direction"),
      row.names = FALSE)
```
