---
title: "SLAPNAP Report"
author: "SLAPNAP Team"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: bookdown::html_document2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)

library(magrittr)
library(ggplot2)
library(dplyr)
library(tidyr)
library(ROCR)
library(knitr)
library(gridExtra)
library(vimp)
# library(cowplot)

# attempt to read in environment variables
reduce_covs <- Sys.getenv("reduce_covs") == "TRUE"
reduce_outcomes <- Sys.getenv("reduce_outcomes") == "TRUE"
reduce_library <- Sys.getenv("reduce_library") == "TRUE"
reduce_groups <- Sys.getenv("reduce_groups") == "TRUE"
no_cv <- Sys.getenv("no_cv") == TRUE
```

```{r}
source("/home/lib/plotting_functions.R")
# get NAbs names from ENV variable
antibody_string <- Sys.getenv("Nab")
antibodies <- strsplit(antibody_string, split = ";")[[1]]
n_ab <- length(antibodies)

# load data
analysis_data_name <- list.files("/home/dat/analysis")
dat <- read.csv(paste0("/home/dat/analysis/", analysis_data_name), header = TRUE)

# check missing values
n_row_prev <- nrow(dat)
dat <- dat[complete.cases(dat),]
n_row_now <- nrow(dat)
```

```{r load_cvfit_objects}
cvfit_ic50 <- readRDS("/home/slfits/cvfit_pc.ic50.rds")
class(cvfit_ic50) <- "myCV.SuperLearner"
if(!reduce_outcomes){
	cvfit_ic80 <- readRDS("/home/slfits/cvfit_pc.ic80.rds")
	cvfit_iip <- readRDS("/home/slfits/cvfit_iip.rds")
	cvfit_dichotomous.1 <- readRDS("/home/slfits/cvfit_dichotomous.1.rds")
	cvfit_dichotomous.2 <- readRDS("/home/slfits/cvfit_dichotomous.2.rds")
	class(cvfit_ic80) <- class(cvfit_iip) <- class(cvfit_dichotomous.1) <-
		class(cvfit_dichotomous.2) <- "myCV.SuperLearner"
}

rslt_ic50 <- get_est_and_ci(cvfit_ic50, Rsquared = TRUE)
rslt_ic80 <- get_est_and_ci(cvfit_ic80, Rsquared = TRUE)
rslt_iip <- get_est_and_ci(cvfit_iip, Rsquared = TRUE)
rslt_dichot1 <- get_est_and_ci(cvfit_dichotomous.1)
rslt_dichot2 <- get_est_and_ci(cvfit_dichotomous.2)

# # get summary measures for executive summary
# sum_ic50 <- summary(cvfit_ic50, Rsquared = TRUE, method = "method.CC_LS")
# sum_ic80 <- summary(cvfit_ic80, Rsquared = TRUE, method = "method.CC_LS")
# sum_iip <- summary(cvfit_iip, Rsquared = TRUE, method = "method.CC_LS")
# sum_dichot1 <- summary(cvfit_dichotomous.1, Rsquared = FALSE, method = "method.AUC")
# sum_dichot2 <- summary(cvfit_dichotomous.2, Rsquared = FALSE, method = "method.AUC")
```

# Executive summary

The NAbs studied in this analysis are `r antibodies`. There were `r n_row_prev` observations extracted from the CATNAP database. There were `r n_row_now` observations with complete sequence data that were used in the analysis.

```{r rsquaredtable}
rsqtab <- rbind(unlist(rslt_ic50), unlist(rslt_ic80), unlist(rslt_iip))
row.names(rsqtab) <- c("IC-50","IC-80","IIP")
kable(rsqtab, col.names = c(expression(CV-R^2), "Lower 95% CI", "Upper 95% CI"),
      digits = 3, row.names = TRUE,
      caption = "Estimates of cross-validated R-squared for super learner predictions of the three continuous-valued outcomes")
```

```{r auctable}
auctab <- rbind(unlist(rslt_dichot1), unlist(rslt_dichot2))
row.names(auctab) <- c("Estimated sensitivity", "Multiple sensitivity")
kable(auctab, col.names = c("CV-AUC", "Lower 95% CI", "Upper 95% CI"),
      digits = 3, row.names = TRUE,
      caption = "Estimates of cross-validated AUC for super learner predictions of the two dichotomous outcomes")
```

The estimated cross-validated $R^2$ of the super learner for predicting continuous outcomes are shown in Table \@ref(tab:rsquaredtable). The estimated cross-validated area under the receiver operating characteristic curve (AUC) of the super learner for predicting binary sensitivity measures are shown in Table \@ref(tab:auctable).

```{r group_vimp_continuous, fig.cap = "Group variable importance for continuous outcomes", fig.height = 10, fig.width = 10}
source("/home/lib/plot_one_vimp.R")
continuous_outcome_vimp <- readRDS("/home/slfits/continuous_outcome_vimp.rds")
x_lab <- expression(paste("Difference in ", R^2, sep = ""))
x_lim <- c(0, 1)
## create a plot for each continuous outcome
# paste0("Variable importance: ", vimp_plot_name(x)) # makes title too long
continuous_outcome_vimp_plots <- lapply(continuous_outcome_vimp, function(x) plot_one_vimp(x, title = vimp_plot_name(x), x_lab = x_lab, x_lim = x_lim))
grob_lst <- continuous_outcome_vimp_plots
if (!no_cv) {
    x_lab_cv <- expression(paste("Difference in cross-validated ", R^2, sep = ""))
    continuous_outcome_cv_vimp <- readRDS("/home/slfits/continuous_outcome_cv_vimp.rds")
    continuous_outcome_cv_vimp_plots <- lapply(continuous_outcome_cv_vimp, function(x) plot_one_vimp(x, title = vimp_plot_name(x), x_lab = x_lab_cv, x_lim = x_lim))
    grob_lst <- c(grob_lst, continuous_outcome_cv_vimp_plots)
}
do.call(grid.arrange, grob_lst)
```

```{r group_vimp_binary, fig.cap = "Group variable importance for binary outcomes", fig.height = 10, fig.width = 10}
source("/home/lib/plot_one_vimp.R")
binary_outcome_vimp <- readRDS("/home/slfits/binary_outcome_vimp.rds")
x_lab <- expression(paste("Difference in ", AUC, sep = ""))
x_lim <- c(0, 1)
## create a plot for each binary outcome
binary_outcome_vimp_plots <- lapply(binary_outcome_vimp, function(x) plot_one_vimp(x, title = vimp_plot_name(x), x_lab = x_lab, x_lim = x_lim))
grob_lst <- binary_outcome_vimp_plots
if (!no_cv) {
    x_lab_cv <- expression(paste("Difference in cross-validated ", AUC, sep = ""))
    binary_outcome_cv_vimp <- readRDS("/home/slfits/binary_outcome_cv_vimp.rds")
    binary_outcome_cv_vimp_plots <- lapply(binary_outcome_cv_vimp, function(x) plot_one_vimp(x, title = vimp_plot_name(x), x_lab = x_lab_cv, x_lim = x_lim))
    grob_lst <- c(grob_lst, binary_outcome_cv_vimp_plots)
}
do.call(grid.arrange, grob_lst)
```

The estimated variable importance of the groups defined in [table?] for predicting the continuous outcomes, with respect to the difference in nonparametric $R^2$, is shown in Figure \@ref(fig:group_vimp_continuous). The estimated variable importance of these groups for predicting the binary outcomes, with respect to the difference in nonparametric AUC, is shown in Figure \@ref(fig:group_vimp_binary).

# Summary of endpoints

Histograms of IC-50 and IC-80 for each individual NAb are shown in Figure \@ref(fig:histic50) and Figure \@ref(fig:histic80), respectively. Histograms for the predicted IC-50 an IC-80 based on the additive model are shown in Figure \@ref(fig:histcombn), while a histogram of the predicted IIP is shown in Figure \@ref(fig:histiip).

```{r histic50, fig.cap = "Histogram of IC50 values for individual NAbs", fig.height=5}
ic50_hist <- list()
ic50_tab <- list()
ct <- 0
for(i in seq_len(n_ab)){
	ct <- ct + 1
	this_name <- gsub("-", ".", paste0(antibodies[i], ".ic50.imputed"))
	ic50_hist[[ct]] <- make_hist_plot(dat, var_name = this_name,
	                                  x_lab = paste0("IC-50 ", antibodies[i]),
	                                  y_lab = "Density")
	ic50_tab[[ct]] <- summary(dat[, this_name])[1:6] # to ignore NA columns
	ct <- ct+1
 	dat[,paste0("log10_",this_name)] <- log10(dat[, this_name])
 	ic50_hist[[ct]] <- make_hist_plot(dat, var_name = paste0("log10_",this_name),
 	                                  x_lab = bquote(log[10]~"(IC-50 "~.(antibodies[i])~")"),
 	                                  y_lab = "")
 	ic50_tab[[ct]] <- summary(dat[, paste0("log10_",this_name)])[1:6]
}
do.call(grid.arrange, ic50_hist)
```

```{r tableic50, fig.cap = "Summary statistics of IC-50 values for individual NAbs"}
ic50_table <- Reduce(rbind, ic50_tab)
row.names(ic50_table) <- c(paste0("IC-50 ", antibodies),
                           paste0("log(IC-50 ", antibodies,")"))[c(seq(1,n_ab*2,by=2),seq(2, n_ab*2, by = 2))]
kable(ic50_table, row.names = TRUE, digits = 3)
```

```{r histic80, fig.cap = "Histogram of IC80 values for individual NAbs"}
ic80_hist <- list()
ic80_tab <- list()
ct <- 0
for(i in seq_len(n_ab)){
	ct <- ct + 1
	this_name <- gsub("-", ".", paste0(antibodies[i], ".ic80.imputed"))
	ic80_hist[[ct]] <- make_hist_plot(dat, var_name = this_name,
	                                  x_lab = paste0("IC-80 ", antibodies[i]),
	                                  y_lab = "Density")
	ic80_tab[[ct]] <- summary(dat[, this_name])[1:6] # to ignore NA columns
	ct <- ct+1
 	dat[,paste0("log10_",this_name)] <- log10(dat[, this_name])
 	ic80_hist[[ct]] <- make_hist_plot(dat, var_name = paste0("log10_",this_name),
	                                  x_lab = bquote(log[10]~"(IC-80 "~.(antibodies[i])~")"),
	                                  y_lab = "")
 	ic80_tab[[ct]] <- summary(dat[, paste0("log10_",this_name)])[1:6]
}
do.call(grid.arrange, ic80_hist)
```

```{r tableic80, fig.cap = "Summary statistics of IC-80 values for individual NAbs"}
ic80_table <- Reduce(rbind, ic80_tab)
row.names(ic80_table) <- c(paste0("IC-80 ", antibodies),
                           paste0("log(IC-80 ", antibodies,")"))[c(seq(1,n_ab*2,by=2),seq(2, n_ab*2, by = 2))]
kable(ic80_table, row.names = TRUE, digits = 3)
```


```{r histcombn, fig.cap = "Histogram of estimated IC50 and IC80 for combined NAbs. Top row = original scale; bottom row = log10 scale"}
combn_hist <- list()
combn_hist[[1]] <- make_hist_plot(dat, "pc.ic50", "Estimated IC-50", "Density")
combn_hist[[2]] <- make_hist_plot(dat, "log10.pc.ic50", bquote(log[10]~"(estimated IC-50)"), "")
combn_hist[[3]] <- make_hist_plot(dat, "pc.ic80", "Estimated IC-80", "Density")
combn_hist[[4]] <- make_hist_plot(dat, "log10.pc.ic80", bquote(log[10]~"(estimated IC-80)"), "")
do.call(grid.arrange, combn_hist)
```

```{r histiip, fig.cap = "Estimated IIP for combined NAbs"}
iip_hist <- list()
iip_hist[[1]] <- make_hist_plot(dat, "iip", "Estimated IIP", "Density")
# dat$log10.iip <- log10(dat$iip)
# iip_hist[[2]] <- make_hist_plot(dat, "log10.iip", bquote(log[10]~"(estimated IIP)"), "")
do.call(grid.arrange, iip_hist)
```

```{r combn_table}
# make a table of ic50 80 and iip for combined NAbs
combn_table <- rbind(
  summary(dat$pc.ic50)[1:6],
  summary(dat$log10.pc.ic50)[1:6],
  summary(dat$pc.ic80)[1:6],
  summary(dat$log10.pc.ic80)[1:6],
  summary(dat$iip)[1:6]
)
row.names(combn_table) <- c(
  "Estimated IC-50", "log(estimated IC-50)", "Estimated IC-80", "log(estimated IC-80)", "IIP"
)
kable(combn_table, row.names = TRUE, digits = 3)
```

```{r dichot_outcomes_fig, fig.cap = "Distribution of binary sensitivity outcomes. Estimated indicates whether the estimated IC-50 falls above a sensitivity threshold. Multiple indicates whether at least two individual NAbs fall above a sensitivity threshold."}
n <- n_row_now
# make a stacked data set for easy use of geom_bar
dichot_dat <- data.frame(
  Outcome_type = c("Estimated", "Estimated", "Multiple", "Multiple"),
  Outcome = rep(c("Resistant", "Sensitive"), 2),
  value = 100*c(mean(dat$dichotomous.1), 1 - mean(dat$dichotomous.1),
            mean(dat$dichotomous.2), 1 - mean(dat$dichotomous.2))
)
trans_fill <- c(
  rgb(30, 21, 42, alpha = 255/2, maxColorValue = 255),
  rgb(78, 103, 102, alpha = 255/2, maxColorValue = 255),
  rgb(90,177,187, alpha = 255/2, maxColorValue = 255),
  rgb(165, 200, 130, alpha = 255/2, maxColorValue = 255),
  rgb(247, 221, 114, alpha = 255/2, maxColorValue = 255)
)

fill <- c(
  rgb(30, 21, 42, maxColorValue = 255),
  rgb(78, 103, 102, maxColorValue = 255),
  rgb(90,177,187, maxColorValue = 255),
  rgb(165, 200, 130, maxColorValue = 255),
  rgb(247, 221, 114, maxColorValue = 255)
)

ggplot(dichot_dat, aes(y = value, x = factor(Outcome_type), fill = factor(Outcome))) +
	geom_bar(position = "fill", stat = "identity") +
	scale_fill_manual(values = fill[c(2,4)]) +
	theme_bw() +
	xlab("Sensitivity Measure") +
	geom_text(data = dichot_dat, aes(y = value, label = paste0(round(value, 2), "%"), stat = "identity"),
	          position = position_fill(vjust = 0.5))
```


# Super learner prediction results

A super learner was fit to each outcome. For continuous outcomes, super learner weights were chosen to optimize estimated 10-fold cross-validated MSE; for binary outcomes, weights were chosen to optimize a 10-fold negative log-likelihood risk estimate. The algorithms used in the super learner are shown in Table \@ref(fig:super_learner_library_table).

```{r super_learner_library_table, fig.cap = "Super learner library"}
source("/home/lib/super_learner_libraries.R")
library_table <- data.frame()
this_library <- if(reduce_library){
	default_library_reduced
}else{
	default_library
}
Description <- sapply(this_library, function(x){
	eval(parse(text = paste0("descr_", x)))
})
knitr::kable(as.data.frame(Description))
```

The weights assigned to each algorithm for each outcome are shown in Table \@ref{fig:super_learner_weight_table}. Cross-validated risks for each outcome are shown in the following subsections.

```{r super_learner_weight_table, fig.cap = "Table of super learner weights for each outcome"}
# load super learner fits
outcome_names <- if(!reduce_outcomes){
	c("pc.ic50", "pc.ic80", "iip", "dichotomous.1", "dichotomous.2")
}else{
	c("pc.ic50")
}
weight_list <- vector(mode = "list", length = length(outcome_names))
ct <- 0
for(o in outcome_names){
	ct <- ct + 1
	fit_name <- paste0("fit_", o, ".rds")
	weight_list[[ct]] <- readRDS(paste0("/home/slfits/slweights_", fit_name))
}
weight_table <- data.frame(Reduce(cbind, weight_list))
colnames(weight_table) <- outcome_names
row.names(weight_table) <- this_library
knitr::kable(as.data.frame(weight_table), digits = 2)
```

## IC-50

The cross-validated performance of super learner (in terms of $R^2$) relative to the discrete super learner and candidate algorithms are shown for IC-50 in Figure \@ref(fig:plotic50).

```{r plotic50, fig.cap = "Cross-validated R-squared for estimated IC-50"}
plot(cvfit_ic50, main_title = "IC-50", xlim1 = -0.05, xlim2 = 0.8, text_size = 9,
     method = "method.CC_LS")
# and get correlations
cor_ic50 <- get_cor_pred_outcome(cvfit_ic50)
```

Figure \@ref(fig:plotic50predversusoutcomes) shows cross-validated predictions made by the super learner plotted against outcomes. The Pearson correlation between predictions and true outcomes was `r round(cor_ic50[1], 3)`; the Spearman correlation was `r round(cor_ic50[2], 3)`.

```{r plotic50predversusoutcomes, fig.cap = "Cross-validated super learner predicted IC-50 plotted against actual IC-50 values. Colors correspond to different cross-validation folds"}
plot_cv_predictions(cvfit_ic50, outcome_name = "IC-50", log_axis = FALSE)
```

## IC-80

The cross-validated performance of super learner (in terms of $R^2$) relative to the discrete super learner and candidate algorithms are shown for IC-80 in Figure \@ref(fig:plotic80).

```{r plotic80, fig.cap = "Cross-validated R-squared for estimated IC-80"}
plot(cvfit_ic80, main_title = "IC-80", xlim1 = -0.05, xlim2 = 1, text_size = 9,
     method = "method.CC_LS")
# and get correlations
cor_ic80 <- get_cor_pred_outcome(cvfit_ic80)
```

Figure \@ref(fig:plotic80predversusoutcomes) shows cross-validated predictions made by the super learner plotted against outcomes. The Pearson correlation between predictions and true outcomes was `r round(cor_ic80[1], 3)`; the Spearman correlation was `r round(cor_ic80[2], 3)`.

```{r plotic80predversusoutcomes, fig.cap = "Cross-validated super learner predicted IC-80 plotted against actual IC-80 values. Colors correspond to different cross-validation folds"}
plot_cv_predictions(cvfit_ic80, outcome_name = "IC-80", log_axis = FALSE)
```

## IIP

The cross-validated performance of super learner (in terms of $R^2$) relative to the discrete super learner and candidate algorithms are shown for IIP in Figure \@ref(fig:plotiip).

```{r plotiip, fig.cap = "Cross-validated R-squared for estimated IIP"}
plot(cvfit_iip, main_title = "IIP", xlim1 = -0.05, xlim2 = 1, text_size = 9,
     method = "method.CC_LS")
# and get correlations
cor_iip <- get_cor_pred_outcome(cvfit_iip)
```

Figure \@ref(fig:plotiippredversusoutcomes) shows cross-validated predictions made by the super learner plotted against outcomes. The Pearson correlation between predictions and true outcomes was `r round(cor_iip[1], 3)`; the Spearman correlation was `r round(cor_iip[2], 3)`.

```{r plotiippredversusoutcomes, fig.cap = "Cross-validated super learner predicted IIP plotted against actual IIP values. Colors correspond to different cross-validation folds"}
plot_cv_predictions(cvfit_iip, outcome_name = "IIP", log_axis = FALSE)
```

## Dichotomous sensitivity 1

The cross-validated performance of super learner (in terms of AUC) relative to the discrete super learner and candidate algorithms are shown for the first dichotomous endpoint (estimated IC-50 above sensitivity threshold) in Figure \@ref(fig:plotdichot1). Figure \@ref(fig:rocdichot1) shows cross-validated ROC curves for this endpoint.

```{r plotdichot1, fig.cap = "Cross-validated AUC for predicting sensitivity based on estimated IC-50"}
plot(cvfit_dichotomous.1, main_title = "", xlim1 = 0.4, xlim2 = 1, text_size = 9,
     Rsquared = FALSE, method = "method.AUC")
```

```{r rocdichot1, fig.cap = "Cross-validated ROC curve for the super learner, discrete super learner, and single best performing algorithm for predicting sensitivity based on estimated IC-50"}
plot_roc_curves(cvfit_dichotomous.1)
```

```{r predprob1, fig.cap = "Predicted probabilities for resistant and sensitive viruses for the super learner, discrete super learner, and single best performing algorithm."}
plot_predicted_prob_boxplots(cvfit_dichotomous.1, cols = trans_fill[c(2,4)])
```

## Dichotomous sensitivity 2

The cross-validated performance of super learner (in terms of AUC) relative to the discrete super learner and candidate algorithms are shown for the second dichotomous endpoint (each individual IC-50 above threshold) in Figure \@ref(fig:plotdichot2). Figure \@ref(fig:rocdichot2) shows cross-validated ROC curves for this endpoint.

```{r plotdichot2, fig.cap = "Cross-validated AUC for predicting sensitivity based on sensitivity to individual NAbs"}
plot(cvfit_dichotomous.2, main_title = "", xlim1 = 0.4, xlim2 = 1, text_size = 9,
     Rsquared = FALSE, method = "method.AUC")
```

```{r rocdichot2, fig.cap = "Cross-validated ROC curve for the super learner, discrete super learner, and single best performing algorithm for predicting sensitivity based on sensitivity to individual NAbs"}
plot_roc_curves(cvfit_dichotomous.2)
```
