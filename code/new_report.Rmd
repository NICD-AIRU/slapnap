---
title: 'SLAPNAP Report: `r format(strsplit(Sys.getenv("Nab"), split = ";")[[1]])`'
author: "SLAPNAP Team"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: bookdown::html_document2
header-includes:
   - \usepackage{subfig}
---

```{r setup, include=FALSE}
in_container <- TRUE
if(in_container){
  code_dir <- "/home/lib/"
  slfits_dir <- "/home/slfits/"
  data_dir <- "/home/dat/"
}else{
  code_dir <- "~/Dropbox/Emory/AMP/slapnap/code/"
  slfits_dir <- "~/Dropbox/Emory/AMP/slapnap/slfits/"
  data_fit <- "~/Dropbox/Emory/AMP/slapnap/data/"
}
source(paste0(code_dir, "report_preamble.R"))
library(ggplot2)
library(grid)
```

```{r get_options}
opts <- get_global_options() 
any_cont <- any(c("ic50", "ic80") %in% opts$outcomes)
any_dich <- any(c("sens1", "sens2") %in% opts$outcomes)
# read in number of observations
nprevious <- readRDS(paste0(slfits_dir, "nprevious.rds"))
ncomplete <- readRDS(paste0(slfits_dir, "ncomplete.rds"))
# read in data
analysis_data_name <- list.files(paste0(data_dir, "analysis"))
dat <- read.csv(paste0(data_dir, "analysis/", analysis_data_name), header = TRUE)
dat <- dat[complete.cases(dat),]

# make nice outcome names
all_outcomes <- c("ic50", "ic80", "iip", "sens1", "sens2")
all_labels <- c("IC-50", "IC-80", "IIP", "Estimated", "Multiple")
nice_outcomes <- opts$outcomes
for(i in seq_along(all_outcomes)){
    nice_outcomes <- gsub(all_outcomes[i], all_labels[i], nice_outcomes)
}
# now format continuous outcomes table
cont_idx <- which(opts$outcomes %in% c("ic50", "ic80", "iip"))
bin_idx <- which(opts$outcomes %in% c("sens1", "sens2"))
cont_nms <- nice_outcomes[cont_idx]
bin_nms <- nice_outcomes[bin_idx]
```

# Executive summary

The NAbs studied in this analysis are `r paste0(antibodies, collapse = ", ")`. There were `r nprevious` sequences extracted from the CATNAP database; `r ncomplete` sequences had complete data and were used in the analysis. The analysis considered `r length(opts$outcomes)` `r ifelse(length(opts$outcomes) == 1, "measure", "measures")` of sensitivity: `r get_comma_sep_outcomes(opts)`. `r get_outcome_descriptions(opts)`

Prediction of each outcome was performed using `r get_learner_descriptions(opts)`

The specific `r ifelse(length(opts$learners) > 1 | opts$cvtune == TRUE, "algorithms", "algorithm")` used in learning process `r ifelse(length(opts$learners) == 1 | opts$cvtune == TRUE, "are", "is")` described in Table \@ref(tab:sllibtab).

```{r sllibtab}
source("/home/lib/super_learner_libraries.R")
this_library <- make_sl_library_vector(opts)
Description <- sapply(this_library, function(x){
  eval(parse(text = paste0("descr_", x)))
})
Description <- data.frame(Label = names(Description), Description = Description)
row.names(Description) <- NULL
kable(as.data.frame(Description), col.names = c("Label", "Description"),
             caption = ifelse(length(opts$learners) == 1, 
                              "Algorithms used in the analysis",
                              "Algorithms used in the super learner library"))
```

`r if(length(opts$learners) == 1) "-->"`

`r if(!opts$cvperf) "<!--"`

```{r}
fit_list_out <- load_cv_fits(opts)
cv_outcomes <- get_cv_outcomes_tables(fit_list_out)
```

The predictive ability of the learner was assessed using cross-validation. `r if(any_cont) "The estimated cross-validated $R^2$ of the super learner for predicting continuous outcomes are shown in Table \\@ref(tab:rsquaredtable)."` `r if(any_dich) "The estimated cross-validated area under the receiver operating characteristic curve (AUC) of the super learner for predicting binary sensitivity measures are shown in Table \\@ref(tab:auctable)."` 

```{r rsquaredtable, eval = any_cont}
get_cv_outcomes_tables(fit_list_out)[[1]]
```

```{r auctable, eval = any_cont}
# apparently no way around calling this function multiple times
# otherwise the labeling messes up
get_cv_outcomes_tables(fit_list_out)[[2]]
```

`r if(any_dich) "The estimated cross-validated area under the receiver operating characteristic curve (AUC) of the super learner for predicting binary sensitivity measures are shown in Table \\@ref(tab:auctable)."`

`r if(!("ic50" %in% opts$outcomes)) "<!--"`

`r if(!opts$cvperf) "-->"`

<!-- If we did conditional group variable importance, print the next section -->
`r if (!("cond" %in% opts$importance_grp)) "<!--"`
In Table \@ref(tab:vimpgrpcond), we display the groups of variables and their ranked conditional population variable importance for predicting `r ifelse(length(opts$outcomes) == 1, get_comma_sep_outcomes(opts), "each outcome.")` For variable group definitions, please refer to Table \@ref(tab:vimpGroupTab).

```{r vimpgrpcond, eval = "cond" %in% opts$importance_grp}
## vimp_summary_tbl created in preamble
vimp_summary_cond <- vimp_summary_tbl$grp_cond %>%
    select(-mn_rank)
correct_outcomes <- ifelse(length(opts$outcomes) == 1, get_comma_sep_outcomes(opts), "each outcome.")
cont_nm_descr <- ifelse(length(cont_nms) > 0, ifelse(length(cont_nms) == 1, "R^2", paste0("R^2 for continuous outcomes (", paste(cont_nms, collapse = ", "), ")")), "")
bin_nm_descr <- ifelse(length(bin_nms) > 0, ifelse(length(bin_nms) == 1, "AUC", paste0("AUC for binary outcomes (", paste(bin_nms, collapse = ", "), ")")), "")
correct_description <- paste0(" Importance is measured via ", cont_nm_descr, ifelse(length(cont_nms) > 0 & length(bin_nms) > 0, " and ", ""), bin_nm_descr, ".")
## make the table
kable(vimp_summary_cond, col.names = c("Variable group", colnames(vimp_summary_cond)[-1]), caption = paste0("Ranked conditional variable importance of groups relative to the remaining features for predicting ", correct_outcomes, correct_description, " A total of ", n_row_now, " pseudoviruses with complete information were used in this analysis. To estimate the prediction function based on all available features, we used the ", num_obs_full, " observations with complete sequence data; to estimate the prediction function based on the reduced set of features, we used the remaining ", num_obs_red, " observations with complete sequence data."))
```

`r if (!("cond" %in% opts$importance_grp)) "-->"`

<!-- If we did marginal group variable importance, print the next section -->
`r if (!("marg" %in% opts$importance_grp)) "<!--"`
In Table \@ref(tab:vimpgrpmarg), we display the groups of variables and their ranked marginal population variable importance for predicting `r ifelse(length(opts$outcomes) == 1, get_comma_sep_outcomes(opts), "each outcome.")` For variable group definitions, please refer to Table \@ref(tab:vimpGroupTab).

```{r vimpgrpmarg, eval = "marg" %in% opts$importance_grp}
## vimp_summary_tbl created in preamble
vimp_summary_marg <- vimp_summary_tbl$grp_marg %>%
    select(-mn_rank)
correct_outcomes <- ifelse(length(opts$outcomes) == 1, get_comma_sep_outcomes(opts), "each outcome.")
cont_nm_descr <- ifelse(length(cont_nms) > 0, ifelse(length(cont_nms) == 1, "R^2", paste0("R^2 for continuous outcomes (", paste(cont_nms, collapse = ", "), ")")), "")
bin_nm_descr <- ifelse(length(bin_nms) > 0, ifelse(length(bin_nms) == 1, "AUC", paste0("AUC for binary outcomes (", paste(bin_nms, collapse = ", "), ")")), "")
correct_description <- paste0(" Importance is measured via ", cont_nm_descr, ifelse(length(cont_nms) > 0 & length(bin_nms) > 0, " and ", ""), bin_nm_descr, ".")
## make the table
kable(vimp_summary_marg, col.names = c("Variable group", colnames(vimp_summary_marg)[-1]), caption = paste0("Ranked marginal variable importance of groups relative to the group of geographic confounders predicting ", correct_outcomes, correct_description, " A total of ", n_row_now, " pseudoviruses with complete information were used in this analysis. To estimate the prediction function based on all available features, we used the ", num_obs_full, " observations with complete sequence data; to estimate the prediction function based on the reduced set of features, we used the remaining ", num_obs_red, " observations with complete sequence data."))
```

`r if (!("marg" %in% opts$importance_grp)) "-->"`

<!--
The estimated variable importance of individual features in the Super Learner are shown in Table \@ref(tab:combinedvarimpindividualfeatures). These are features that were deemed important for prediction of at least two of the outcomes. For features associated with each outcome, please refer to the outcomes' respective sections of the report.
=======
# Results for IC-50

## Descriptive statistics

`r if(length(opts$nab) == 1) "<!--"`

Histograms of IC-50 for each individual neutralizing antibody are shown in Figure \@ref(fig:histic50). Related summary measures are shown in Table \@ref(tab:tableic50)

```{r, histic50, eval = ("ic50" %in% opts$outcomes), fig.cap = paste0("Distribution of IC-50 values (n = ", ncomplete, ") for each neutralizing antibody."), fig.height=5}
ic50_descr <- get_individual_nab_summaries("ic50", opts, dat)
do.call(grid.arrange, ic50_descr$hist)
```

```{r, tableic50, eval = ("ic50" %in% opts$outcomes)}
ic50_table <- Reduce(rbind, ic50_descr$summary)
row.names(ic50_table) <- c(paste0("IC-50 ", opts$nab))                           
kable(ic50_table, row.names = TRUE, digits = 3,
      caption = paste0("Summary statistics of IC-50 values for individual NAbs (n = ", ncomplete, " observations with complete sequence data)."))
```

`r if(length(opts$nab) == 1) "-->"`

A summary of the distribution of `r ifelse(length(opts$nab) == 1, "measured", "estimated")` IC-50 for the `r ifelse(length(opts$nab) == 1, "", "combination of")`selected neutralizing `r ifelse(length(opts$nab) == 1, "antibody", "antibodies")` is shown in Figure \@ref(fig:histcombnic50). 

```{r makecapic50}
ic50_figcap <- if(length(opts$nab) == 1){
  paste0("Histogram of IC-50 for the selected neutralizing antibody. Top row = original scale; bottom row = log10 scale (n = ", ncomplete, " observations with complete sequence data).")
}else{
  paste0("Histogram of estimated IC-50 for the combined neutralizing antibodies. Top row = original scale; bottom row = log10 scale (n = ", ncomplete, " observations with complete sequence data).")
}
```

```{r histcombnic50, fig.cap = ic50_figcap}
combn_hist <- list()
combn_hist[[1]] <- make_hist_plot(dat, "pc.ic50", "IC-50", "Density")
combn_hist[[2]] <- make_hist_plot(dat, "log10.pc.ic50", bquote(log[10]~"(IC-50)"), "")
do.call(grid.arrange, combn_hist)
```

`r if(length(opts$learners) == 1) "<!--"`

## Super learner results

The weights assigned to each algorithm for Super Learner predicting IC-50 are shown in Table \@ref(tab:ic50superlearnerweighttable). 

```{r ic50superlearnerweighttable}
weights_ic50 <- readRDS(paste0("/home/slfits/slweights_fit_log10.pc.ic50.rds"))
weight_table <- data.frame(Learner = this_library, Weight = weights_ic50)
row.names(weight_table) <- NULL
# row.names(weight_table) <- this_library # will be defined in executive summary chunk
kable(as.data.frame(weight_table), digits = 2,
             caption = paste0("Table of super learner weights for IC-50 (n = ", ncomplete, " observations with complete sequence data)."))
```

`r if(length(opts$learners) == 1) "-->"`

`r if(!opts$cvperf) "<!--"`

<!-- If we estimated for IC-50, print the next section -->
`r if(!("ic50" %in% opts$outcomes)) "<!--"`

## Predictive performance

`r if(length(opts$learners) == 1 & !opts$cvtune) "<!--"`

`r if(length(opts$learners) == 1) "<!--"`

The cross-validated performance, as measured by $R^2$, of the super learner and constituent algorithms (descriptions of algorithms shown in Table \@ref(tab:sllibtab) in predicting IC-50 are shown in Figure \@ref(fig:plotic50). 

`r if(length(opts$learners) == 1) "-->"`

`r if(length(opts$learners) > 1) "<!--"`

The cross-validated performance, as measured by $R^2$, of the learner (with tuning parameters selected via cross-validation) and of the learner with each individual value of tuning parameters are shown in Figure \@ref(fig:plotic50). 

`r if(length(opts$learners) > 1) "-->"`

```{r plotic50, fig.cap = paste0("Cross-validated R-squared for estimated IC-50 (", ncomplete, " observations with complete sequence data)")}
plot(fit_list_out$out$ic50, main_title = "IC-50", xlim1 = -0.05, xlim2 = 0.8, 
     text_size = 9, method = "method.CC_LS", opts = opts)
```

`r if(length(opts$learners) == 1 & !opts$cvtune) "-->"`

Figure \@ref(fig:plotic50predversusoutcomes) shows cross-validated predictions of IC-50 plotted against observed values of IC-50, colored by cross-validation fold. 

```{r plotic50predversusoutcomes, fig.cap = paste0("Cross-validated super learner predicted IC-50 plotted against actual IC-50 values (", ncomplete, " observations with complete sequence data) . Colors correspond to cross-validation folds.")}
plot_cv_predictions(cv_fit = fit_list_out$out$ic50, outcome_name = "IC-50", log_axis = FALSE)
```

`r if(!opts$cvperf) "-->"`

## Variable importance

### Biological importance

### Predictive importance

`r if(!("ic50" %in% opts$outcomes)) "-->"`

<!-- If we estimated for IC-80, print the next section -->

`r if(!("ic80" %in% opts$outcomes)) "<!--"`

# Results for IC-80

## Descriptive statistics

`r if(length(opts$nab) == 1) "<!--"`

Histograms of IC-80 for each individual neutralizing antibody are shown in Figure \@ref(fig:histic80). Related summary measures are shown in \@ref(tab:tableic80)

```{r, histic80, eval = ("ic80" %in% opts$outcomes), fig.cap = paste0("Distribution of IC-80 values (n = ", ncomplete, ") for each neutralizing antibody."), fig.height=5}
ic80_descr <- get_individual_nab_summaries("ic80", opts, dat)
do.call(grid.arrange, ic80_descr$hist)
```

```{r, tableic80, eval = ("ic80" %in% opts$outcomes)}
ic80_table <- Reduce(rbind, ic80_descr$summary)
row.names(ic80_table) <- c(paste0("IC-80 ", opts$nab))                           
kable(ic80_table, row.names = TRUE, digits = 3,
      caption = paste0("Summary statistics of IC-80 values for individual NAbs (n = ", ncomplete, " observations with complete sequence data)."))
```

`r if(length(opts$nab) == 1) "-->"`

A summary of the distribution of `r ifelse(length(opts$nab) == 1, "measured", "estimated")` IC-80 for the `r ifelse(length(opts$nab) == 1, "", "combination of")`selected neutralizing `r ifelse(length(opts$nab) == 1, "antibody", "antibodies")` is shown in Figure \@ref(fig:histcombnic80). 

```{r makecapic80}
ic80_figcap <- if(length(opts$nab) == 1){
  paste0("Histogram of IC-80 for the selected neutralizing antibody. Top row = original scale; bottom row = log10 scale (n = ", ncomplete, " observations with complete sequence data).")
}else{
  paste0("Histogram of estimated IC-80 for the combined neutralizing antibodies. Top row = original scale; bottom row = log10 scale (n = ", ncomplete, " observations with complete sequence data).")
}
```

```{r histcombnic80, fig.cap = ic80_figcap}
combn_hist <- list()
combn_hist[[1]] <- make_hist_plot(dat, "pc.ic80", "IC-80", "Density")
combn_hist[[2]] <- make_hist_plot(dat, "log10.pc.ic80", bquote(log[10]~"(IC-80)"), "")
do.call(grid.arrange, combn_hist)
```

`r if(length(opts$learners) == 1) "<!--"`

## Super learner results

The weights assigned to each algorithm for Super Learner predicting IC-80 are shown in Table \@ref(tab:ic80superlearnerweighttable). 

```{r ic80superlearnerweighttable}
weights_ic80 <- readRDS(paste0("/home/slfits/slweights_fit_log10.pc.ic80.rds"))
weight_table <- data.frame(Learner = this_library, Weight = weights_ic80)
row.names(weight_table) <- NULL
# row.names(weight_table) <- this_library # will be defined in executive summary chunk
kable(as.data.frame(weight_table), digits = 2,
             caption = paste0("Table of super learner weights for IC-80 (n = ", ncomplete, " observations with complete sequence data)."))
```

`r if(length(opts$learners) == 1) "-->"`

`r if(!opts$cvperf) "<!--"`

## Predictive performance

`r if(length(opts$learners) == 1 & !opts$cvtune) "<!--"`

`r if(length(opts$learners) == 1) "<!--"`

The cross-validated performance, as measured by $R^2$, of the super learner and constituent algorithms (descriptions of algorithms shown in Table \@ref(tab:sllibtab) in predicting IC-80 are shown in Figure \@ref(fig:plotic80). 

`r if(length(opts$learners) == 1) "-->"`

`r if(length(opts$learners) > 1) "<!--"`

The cross-validated performance, as measured by $R^2$, of the learner (with tuning parameters selected via cross-validation) and of the learner with each individual value of tuning parameters are shown in Figure \@ref(fig:plotic80). 

`r if(length(opts$learners) > 1) "-->"`

```{r plotic80, fig.cap = paste0("Cross-validated R-squared for estimated IC-80 (", ncomplete, " observations with complete sequence data)")}
plot(fit_list_out$out$ic80, main_title = "IC-80", xlim1 = -0.05, xlim2 = 0.8, 
     text_size = 9, method = "method.CC_LS", opts = opts)
```

`r if(length(opts$learners) == 1 & !opts$cvtune) "-->"`

Figure \@ref(fig:plotic80predversusoutcomes) shows cross-validated predictions of IC-80 plotted against observed values of IC-80, colored by cross-validation fold. 

```{r plotic80predversusoutcomes, fig.cap = paste0("Cross-validated super learner predicted IC-80 plotted against actual IC-80 values (", ncomplete, " observations with complete sequence data) . Colors correspond to cross-validation folds.")}
plot_cv_predictions(cv_fit = fit_list_out$out$ic80, outcome_name = "IC-80", log_axis = FALSE)
```

`r if(!opts$cvperf) "-->"`

## Variable importance

### Biological importance

### Predictive importance

`r if(!("ic80" %in% opts$outcomes)) "-->"`


`r if(!("iip" %in% opts$outcomes)) "<!--"`

# Results for IIP

## Descriptive statistics

A summary of the distribution of IIP for the `r ifelse(length(opts$nab) == 1, "", "combination of")`selected neutralizing `r ifelse(length(opts$nab) == 1, "antibody", "antibodies")` is shown in Figure \@ref(fig:histcombniip). 

```{r makecapiip}
iip_figcap <- if(length(opts$nab) == 1){
  paste0("Histogram of IIP for the selected neutralizing antibody (n = ", ncomplete, " observations with complete sequence data).")
}else{
  paste0("Histogram of estimated IIP for the combined neutralizing antibodies (n = ", ncomplete, " observations with complete sequence data).")
}
```

```{r histcombniip, fig.cap = iip_figcap}
combn_hist[[1]] <- make_hist_plot(dat, "iip", "IIP", "Density")
do.call(grid.arrange, combn_hist)
```

`r if(length(opts$learners) == 1) "<!--"`

## Super learner results

The weights assigned to each algorithm for Super Learner predicting IC-50 are shown in Table \@ref(tab:ic50superlearnerweighttable). 

```{r iipsuperlearnerweighttable}
weights_iip <- readRDS(paste0("/home/slfits/slweights_fit_iip.rds"))
weight_table <- data.frame(Learner = this_library, Weight = weights_iip)
row.names(weight_table) <- NULL
# row.names(weight_table) <- this_library # will be defined in executive summary chunk
kable(as.data.frame(weight_table), digits = 2,
             caption = paste0("Table of super learner weights for IIP (n = ", ncomplete, " observations with complete sequence data)."))
```

`r if(length(opts$learners) == 1) "-->"`

`r if(!opts$cvperf) "<!--"`

## Predictive performance

`r if(length(opts$learners) == 1 & !opts$cvtune) "<!--"`

`r if(length(opts$learners) == 1) "<!--"`

The cross-validated performance, as measured by $R^2$, of the super learner and constituent algorithms (descriptions of algorithms shown in Table \@ref(tab:sllibtab) in predicting IIP are shown in Figure \@ref(fig:plotiip). 

`r if(length(opts$learners) == 1) "-->"`

`r if(length(opts$learners) > 1) "<!--"`

The cross-validated performance, as measured by $R^2$, of the learner (with tuning parameters selected via cross-validation) and of the learner with each individual value of tuning parameters are shown in Figure \@ref(fig:plotiip). 

`r if(length(opts$learners) > 1) "-->"`

```{r plotiip, fig.cap = paste0("Cross-validated R-squared for estimated IIP (", ncomplete, " observations with complete sequence data)")}
plot(fit_list_out$out$iip, main_title = "IIP", xlim1 = -0.05, xlim2 = 0.8, 
     text_size = 9, method = "method.CC_LS", opts = opts)
```

`r if(length(opts$learners) == 1 & !opts$cvtune) "-->"`

Figure \@ref(fig:plotiippredversusoutcomes) shows cross-validated predictions of IIP plotted against observed values of IIP, colored by cross-validation fold. 

```{r plotiippredversusoutcomes, fig.cap = paste0("Cross-validated super learner predicted IIP plotted against actual IIP values (", ncomplete, " observations with complete sequence data) . Colors correspond to cross-validation folds.")}
plot_cv_predictions(cv_fit = fit_list_out$out$iip, outcome_name = "IIP", log_axis = FALSE)
```

`r if(!opts$cvperf) "-->"`

## Variable importance

### Biological importance

### Predictive importance

`r if(!("iip" %in% opts$outcomes)) "-->"`



`r if(!("sens1" %in% opts$outcomes)) "<!--"`

# Results for estimated sensitivity

## Descriptive statistics

Out of the `r ncomplete` sequeunces, `r sum(dat$dichotomous.1)` were estimated to be resistant to the `r ifelse(length(opts$nab) > 1, "combination of antibodies", "antibody")`, while `r ncomplete - sum(dat$dichotomous.1)` were estimated to be sensitive. 

`r if(length(opts$learners) == 1) "<!--"`

## Super learner results

The weights assigned to each algorithm for Super Learner predicting estimated sensitivity are shown in Table \@ref(tab:sens1superlearnerweighttable). 

```{r sens1superlearnerweighttable, eval = "sens1" %in% opts$outcomes}
weights_sens1 <- readRDS(paste0("/home/slfits/slweights_fit_dichotomous.1.rds"))
weight_table <- data.frame(Learner = this_library, Weight = weights_sens1)
row.names(weight_table) <- NULL
# row.names(weight_table) <- this_library # will be defined in executive summary chunk
kable(as.data.frame(weight_table), digits = 2,
             caption = paste0("Table of super learner weights for estimated sensitivity (n = ", ncomplete, " observations with complete sequence data)."))
```

`r if(length(opts$learners) == 1) "-->"`

`r if(!opts$cvperf) "<!--"`

## Predictive performance

`r if(length(opts$learners) == 1 & "sens1" %in% opts$outcomes) "<!--"`

The cross-validated performance of super learner, as measured by area under the ROC curve, in predicting estimated sensitivity relative to other candidate algorithms is shown  in Figure \@ref(fig:plotdichot1). Figure \@ref(fig:rocdichot1) shows cross-validated ROC curves for this endpoint.

`r if(length(opts$learners) == 1 & "sens1" %in% opts$outcomes) "-->"`

`r if((length(opts$learners) > 1 | !opts$cvtune) & "sens1" %in% opts$outcomes) "<!--"`

The cross-validated performance of the learner with tuning parameters selected via cross-validation, as measured by area under the ROC curve, and learners with each individual value of tuning parameters are shown in Figure \@ref(fig:rocdichot1). 

```{r plotdichot1, fig.cap = paste0("Cross-validated AUC for predicting sensitivity based on estimated IC-50 (n = ", ncomplete, "observations with complete sequence data)."), eval = "sens1" %in% opts$outcomes}
plot(fit_list_out$out$sens1, main_title = "Estimated sensitivity", xlim1 = 0.4, xlim2 = 1, text_size = 9, 
     Rsquared = FALSE, method = "method.AUC", opts = opts)
```

`r if((length(opts$learners) > 1 | !opts$cvtune) & "sens1" %in% opts$outcomes) "-->"`

Figure \@ref(fig:rocdichot1) shows the cross-validated ROC curve for predicting estimated sensitivity. 

```{r roccap1, eval = "sens1" %in% opts$outcomes}
roc_cap <- if(length(opts$learners) > 1){
  paste0("Cross-validated ROC curve for the super learner, discrete super learner, and single best performing algorithm for predicting estimated sensitivity (n = ", ncomplete, " observations with complete sequence data).")
}else if(!opts$cvtune){
  paste0("Cross-validated ROC curve for the specified learner for predicting estimated sensitivity (n = ", ncomplete, " observations with complete sequence data).")
}else{
  paste0("Cross-validated ROC curve for the learner (with tuning parameters selected via cross-validation) for predicting estimated sensitivity (n = ", ncomplete, " observations with complete sequence data).")
}

predprob_cap <- if(length(opts$learners) > 1){
  paste0("Cross-validated predicted probabilities of estimated resistance made by super learner, discrete super learner, and single best performing algorithm colored by cross-validation fold (n = ", ncomplete, " observations with complete sequence data).")
}else if(!opts$cvtune){
  paste0("Cross-validated predicted probabilities of estimated resistance made by the specified learner colored by cross-validation fold (n = ", ncomplete, " observations with complete sequence data).")
}else{
  paste0("Cross-validated predicted probabilities of estimated resistance made by the cross-validation-tuned learner colored by cross-validation fold (n = ", ncomplete, " observations with complete sequence data).")
}
```

```{r rocdichot1, fig.cap = roc_cap, eval = "sens1" %in% opts$outcomes}
plot_roc_curves(fit_list_out$out$sens1, opts = opts)
```

```{r predprob1, fig.cap = predprob_cap, eval = "sens1" %in% opts$outcomes}
plot_predicted_prob_boxplots(cvfit_dichotomous.1, opts = opts)
```

`r if(!opts$cvperf) "-->"`

## Variable importance

### Biological importance

### Predictive importance

`r if(!("sens1" %in% opts$outcomes)) "-->"`


`r if(!("sens2" %in% opts$outcomes)) "<!--"`

# Results for multiple sensitivity

## Descriptive statistics

Out of the `r ncomplete` sequeunces, `r sum(dat$dichotomous.2)` were estimated to be resistant to the `r ifelse(length(opts$nab) > 1, "combination of antibodies", "antibody")`, while `r ncomplete - sum(dat$dichotomous.2)` were estimated to be sensitive. 

## Super learner results

The weights assigned to each algorithm for Super Learner predicting estimated sensitivity are shown in Table \@ref(tab:sens2superlearnerweighttable)\. 

```{r sens2superlearnerweighttable}
weights_sens2 <- readRDS(paste0("/home/slfits/slweights_fit_dichotomous.2.rds"))
weight_table <- data.frame(Learner = this_library, Weight = weights_sens2)
row.names(weight_table) <- NULL
# row.names(weight_table) <- this_library # will be defined in executive summary chunk
kable(as.data.frame(weight_table), digits = 2,
             caption = paste0("Table of super learner weights for multiple sensitivity (n = ", ncomplete, " observations with complete sequence data)."))
```

`r if(length(opts$learners) == 1) "-->"`

`r if(!opts$cvperf) "<!--"`

## Predictive performance

`r if(length(opts$learners) == 1 & !opts$cvtune) "<!--"`

`r if(length(opts$learners) == 1) "<!--"`

The cross-validated performance of super learner, as measured by area under the ROC curve, in predicting multiple sensitivity relative to other candidate algorithms is shown  in Figure \@ref(fig:plotdichot2). Figure \@ref(fig:rocdichot2) shows cross-validated ROC curves for this endpoint.

`r if(length(opts$learners) == 1) "-->"`

`r if(length(opts$learners) > 1) "<!--"`

The cross-validated performance of the learner with tuning parameters selected via cross-validation, as measured by area under the ROC curve, and learners with each individual value of tuning parameters are shown in Figure \@ref(fig:rocdichot2). 

```{r plotdichot2, fig.cap = paste0("Cross-validated AUC for multiple sensitivity (n = ", ncomplete, "observations with complete sequence data).")}
plot(fit_list_out$out$sens2, main_title = "Multiple sensitivity", xlim1 = 0.4, xlim2 = 1, text_size = 9, 
     Rsquared = FALSE, method = "method.AUC", opts = opts)
```

`r if(length(opts$learners) > 1) "-->"`

Figure \@ref(fig:rocdichot2) shows the cross-validated ROC curve for predicting estimated sensitivity. 

```{r roccap2}
roc_cap <- if(length(opts$learners) > 1){
  paste0("Cross-validated ROC curve for the super learner, discrete super learner, and single best performing algorithm for predicting multiple sensitivity (n = ", ncomplete, " observations with complete sequence data).")
}else if(!opts$cvtune){
  paste0("Cross-validated ROC curve for the specified learner for predicting multiple sensitivity (n = ", ncomplete, " observations with complete sequence data).")
}else{
  paste0("Cross-validated ROC curve for the learner (with tuning parameters selected via cross-validation) for predicting multiple sensitivity (n = ", ncomplete, " observations with complete sequence data).")
}

predprob_cap <- if(length(opts$learners) > 1){
  paste0("Cross-validated predicted probabilities of multiple resistance made by super learner, discrete super learner, and single best performing algorithm colored by cross-validation fold (n = ", ncomplete, " observations with complete sequence data).")
}else if(!opts$cvtune){
  paste0("Cross-validated predicted probabilities of multiple resistance made by the specified learner colored by cross-validation fold (n = ", ncomplete, " observations with complete sequence data).")
}else{
  paste0("Cross-validated predicted probabilities of multiple resistance made by the cross-validation-tuned learner colored by cross-validation fold (n = ", ncomplete, " observations with complete sequence data).")
}
```

```{r rocdichot2, fig.cap = roc_cap}
plot_roc_curves(fit_list_out$out$sens2, opts = opts)
```

```{r predprob2, fig.cap = predprob_cap}
plot_predicted_prob_boxplots(fit_list_out$out$sens2, opts = opts)
```

`r if(length(opts$learners) == 1 & !opts$cvtune) "-->"`

`r if(!opts$cvperf) "-->"`

## Variable importance

### Biological importance

### Predictive importance

`r if(!("sens2" %in% opts$outcomes)) "-->"`